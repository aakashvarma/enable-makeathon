{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.utils import np_utils\n",
    "import urllib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.request import urlopen\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 200 \n",
    "img_cols = 200\n",
    "img_channels = 1\n",
    "batch_size = 1\n",
    "nb_classes = 5\n",
    "nb_epoch = 15\n",
    "nb_filters = 32\n",
    "pool_shape = 2\n",
    "filter_shape = 3\n",
    "output = [\"OK\", \"NOTHING\",\"PEACE\", \"PUNCH\", \"STOP\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_rows*img_cols])\n",
    "x_shaped = tf.reshape(x, [1, img_rows, img_cols, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input_data, img_channels, nb_filters, filter_shape, pool_shape, name):\n",
    "    conv_filter_shape = [filter_shape, filter_shape, img_channels, nb_filters]\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev = 0.03), name = name+'_W')\n",
    "    bias = tf.Variable(tf.truncated_normal([nb_filters]), name=name+'_b')\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    out_layer += bias\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "    ksize = [1, pool_shape, pool_shape, 1]\n",
    "    strides = [1, 2, 2, 1]\n",
    "    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = conv_layer(x_shaped, img_channels, nb_filters, filter_shape, pool_shape, name = 'layer1')\n",
    "layer2 = conv_layer(layer1, 32, nb_filters, filter_shape, pool_shape, name = 'layer2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = tf.reshape(layer2, [-1, 80000])\n",
    "\n",
    "wd1 = tf.Variable(tf.truncated_normal([80000, 128], stddev=0.03), name='wd1')\n",
    "bd1 = tf.Variable(tf.truncated_normal([128], stddev=0.01), name='bd1')\n",
    "dense_layer1 = tf.matmul(flattened, wd1) + bd1\n",
    "dense_layer1 = tf.nn.relu(dense_layer1)\n",
    "\n",
    "wd2 = tf.Variable(tf.truncated_normal([128, 5], stddev=0.03), name='wd2')\n",
    "bd2 = tf.Variable(tf.truncated_normal([5], stddev=0.01), name='bd2')\n",
    "dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n",
    "y_ = tf.nn.softmax(dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = dense_layer2, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "os.chdir(\"D:\\Coding\\CNN-hand-gesture-detection\")\n",
    "print (os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modlistdir(path):\n",
    "    listing = os.listdir(path)\n",
    "    retlist = []\n",
    "    for name in listing:\n",
    "        if name.startswith('.'):\n",
    "            continue\n",
    "        retlist.append(name)\n",
    "    return retlist\n",
    "    \n",
    "\n",
    "\n",
    "path2 = './leapmotion_dataset'\n",
    "imlist = modlistdir(path2)\n",
    "\n",
    "image1 = np.array(Image.open(path2 +'/' + imlist[0])) \n",
    "\n",
    "m,n = image1.shape[0:2] \n",
    "total_images = len(imlist) \n",
    "\n",
    "immatrix = np.array([np.array(Image.open(path2+ '/' + images).convert('L')).flatten()\n",
    "                        for images in imlist], dtype = 'f')\n",
    "\n",
    "\n",
    "\n",
    "print (immatrix.shape)\n",
    "\n",
    "label=np.ones((total_images,),dtype = int)\n",
    "\n",
    "samples_per_class = int(total_images / nb_classes)\n",
    "print (\"samples_per_class - \",samples_per_class)\n",
    "s = 0\n",
    "r = int(samples_per_class)\n",
    "for classIndex in range(nb_classes):\n",
    "    label[s:r] = classIndex\n",
    "    s = r\n",
    "    r = s + samples_per_class\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "(X, Y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "#print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "with sess.as_Default():\n",
    "    total_batch = int(total_images / batch_size)\n",
    "    for epoch in range(nb_epoch):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x = tf.train.batch(list(X_train), batch_size=batch_size)\n",
    "            batch_y = tf.train.batch(list(Y_train), batch_size=batch_size)\n",
    "            o, c = sess.run([optimiser, cross_entropy], feed_dict={x: list(batch_x), y: list(batch_y)})\n",
    "            avg_cost += c / total_batch\n",
    "        test_acc = sess.run(accuracy, feed_dict={x: list(X_test), y: list(Y_test)})\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \"test accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(sess.run(accuracy, feed_dict={x: list(X_test), y: list(Y_test)}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
